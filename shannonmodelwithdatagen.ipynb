{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shannonmodelwithdatagen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0svC4GekZUz",
        "colab_type": "text"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbvqU_G3trVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "#data\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "import pandas as pd\n",
        "import statistics\n",
        "import math\n",
        "import dask.array as da\n",
        "\n",
        "#model\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.losses import mean_squared_error\n",
        "\n",
        "#images\n",
        "import skimage\n",
        "from PIL import Image, ImageEnhance\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, load_img\n",
        "\n",
        "#visualization\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM6IC8NOAPVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#access drive files\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7pFKJ3jRZzW",
        "colab_type": "text"
      },
      "source": [
        "##Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu8-kDcrbY54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def determine_letter(l):\n",
        "  '''determines the corret letter for the filename\n",
        "        l: the number that corresponds to a letter that will be returned\n",
        "  '''\n",
        "    if l == 0:\n",
        "        return \"A\"\n",
        "    if l == 1:\n",
        "        return \"B\"\n",
        "    if l == 2:\n",
        "        return \"C\"\n",
        "    if l == 3:\n",
        "        return \"D\"\n",
        "    if l == 4:\n",
        "        return \"E\"\n",
        "    if l == 5:\n",
        "        return \"F\"\n",
        "    if l == 6:\n",
        "        return \"G\"\n",
        "    else:\n",
        "        return \"H\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCLKY2SWhU7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def determine_word(p, d, l, n):\n",
        "  '''determines whether or not the filename includes the word \"Phase\" or \"Default0\"\n",
        "        p: passage of the mouse of the current sample\n",
        "        d: diet of the mouse of the current sample\n",
        "        l: letter of the mouse of the current sample's well\n",
        "        n: number of the mouse of the current sample's well\n",
        "  '''\n",
        "  returned = \"Phase\";\n",
        "\n",
        "  if passage == \"1\" and l != \"A\" and l != \"E\":\n",
        "    if diet == \"MD\":\n",
        "      if n == 9 or n == 10 or n == 11 or n == 12:\n",
        "          returned = \"Default0\"\n",
        "    else:\n",
        "      returned = \"Default0\"\n",
        "  \n",
        "  if passage == \"7\" and l != \"A\" and l != \"E\":\n",
        "    if diet == \"MD\" and (n == 1 or n == 2 or n == 3 or n == 4):\n",
        "      returned = \"Default0\"\n",
        "  \n",
        "  if passage == \"7\" and diet == \"STD\":\n",
        "    if l == \"A\" or l == \"E\":\n",
        "      returned = \"Default0\"\n",
        "    elif n != 5 and n != 6 and n != 7 and n != 8:\n",
        "      returned = \"Default0\"\n",
        "  \n",
        "  return returned"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN9x-EZmhZUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#put all the image filenames in an array\n",
        "X = []\n",
        "\n",
        "for p in range(0,2): #passage\n",
        "    for d in range(0,2): #diet\n",
        "        for l in range(0,8): #letter\n",
        "            for n in range(1,13): #number\n",
        "                image_set = [] #each set has 25 images\n",
        "            \n",
        "                for i in range(0,25): #image number\n",
        "                    if p == 0:\n",
        "                        passage = \"1\"\n",
        "                    else:\n",
        "                        passage = \"7\"\n",
        "                    if d == 0:\n",
        "                        diet = \"STD\"\n",
        "                    else:\n",
        "                        diet = \"MD\"\n",
        "\n",
        "                    letter = determine_letter(l)\n",
        "\n",
        "                    im = ('''data not publicly available''')\n",
        "\n",
        "                    #append to image set array\n",
        "                    X.append(im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNW3oAkuQWk1",
        "colab_type": "text"
      },
      "source": [
        "##Diversity indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUqqOBBkT9bR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#access the diversity spreadsheet\n",
        "diversity_sheet = pd.read_excel('''data not publicly available''')\n",
        "\n",
        "#drop all columns except for diets, wells, and shannon diversity indices\n",
        "diversity_sheet = diversity_sheet.drop([\"Unnamed: 2\",\"Unnamed: 3\",\"Unnamed: 4\",\n",
        "                                          \"Unnamed: 5\", \"T7\", \"Unnamed: 8\", \n",
        "                                           \"T1\", \"Unnamed: 11\"], axis = 1)\n",
        "\n",
        "#rename the remaining columns\n",
        "diversity_sheet = diversity_sheet[1:]\n",
        "diversity_sheet.columns = [\"diet\", \"well\", \"p7 diversity\", \"p1 diversity\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nty5zVNF7uX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data frame without diversities\n",
        "sheet = diversity_sheet.drop([\"p1 diversity\", \"p7 diversity\"], axis = 1)\n",
        "\n",
        "#data frame for p1 diversities\n",
        "diversity_sheet_p1 = sheet.copy()\n",
        "diversity_sheet_p1[\"passage\"] = \"1\"\n",
        "diversity_sheet_p1[\"diversity\"] = diversity_sheet[\"p1 diversity\"]\n",
        "\n",
        "#data frame for p7 diversities\n",
        "diversity_sheet_p7 = sheet.copy()\n",
        "diversity_sheet_p7[\"passage\"] = \"7\"\n",
        "diversity_sheet_p7[\"diversity\"] = diversity_sheet[\"p7 diversity\"]\n",
        "\n",
        "#combine the data frames\n",
        "diversity_sheet = diversity_sheet_p1.append(diversity_sheet_p7, \n",
        "                    ignore_index = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q9IFeMYNTkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = np.array(diversity_sheet[\"diversity\"])\n",
        "\n",
        "length = len(Y) #to make sure max index for loop doesn't change\n",
        "    \n",
        "for index in range(length):\n",
        "    new_index = index*25\n",
        "    rows = [Y[new_index]] * 24\n",
        "    Y = np.insert(Y, new_index+1, rows)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL6Xsso9CItD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#add the image columns to the diversity dataframe\n",
        "data = pd.DataFrame({'X': X, 'Y': Y})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2_UnwNNh6eH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop all rows with shannon diversity index of 0\n",
        "data = data[data[\"Y\"] != 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y63JGNFh8rs",
        "colab_type": "text"
      },
      "source": [
        "##Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gkd653cqVoIK",
        "colab": {}
      },
      "source": [
        "#split into input/output arrays\n",
        "X = np.array(data[\"X\"].tolist())\n",
        "Y = np.array(data[\"Y\"].tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIZAN_-Nlz2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "partition = {}\n",
        "train = []\n",
        "valid = []\n",
        "test = []\n",
        "\n",
        "samples = len(X)/25 #each sample has 25 images\n",
        "len_tr = (int(samples*0.6))*25 #all 25 images should be in the same set\n",
        "len_val = (int((samples-(len_tr/25))/2))*25\n",
        "len_test = int((samples*25)-len_tr-len_val)\n",
        "\n",
        "for i in range(len_tr):\n",
        "  train.append(X[i])\n",
        "\n",
        "for i in range(len_tr, len_val+len_tr):\n",
        "  valid.append(X[i])\n",
        "\n",
        "for i in range(len_val+len_tr, len_test+len_val+len_tr): \n",
        "  test.append(X[i])\n",
        "\n",
        "partition['train'] = train\n",
        "partition['valid'] = valid\n",
        "partition['test'] = test\n",
        "\n",
        "values = {}\n",
        "for i in range(len(X)):\n",
        "  values[X[i]] = Y[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-FcvMd53W4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(Sequence):\n",
        "    '''generates data for the model'''\n",
        "    \n",
        "    def __init__(self, list_IDs, values, batch_size=32, dim=(640, 540), n_channels=3, shuffle=True):\n",
        "      '''initializes all the variables\n",
        "          list_IDs: the list of all the IDs in the dataset (filenames)\n",
        "          values: the list of all the diversity indices\n",
        "      '''\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.values = values\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_channels = n_channels\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        '''determines the number of batches per epoch'''\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      '''generates one batch of data\n",
        "            index: the batch's index\n",
        "      '''\n",
        "        #generate the batch indices\n",
        "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        #get the IDs with the specified indices\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indices]\n",
        "\n",
        "        #generate the data from the specified IDs\n",
        "        X, Y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, Y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        '''updates indices after each epoch'''\n",
        "        self.indices = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "      '''generates the set of data containing batch_size samples\n",
        "            list_IDs_temp: the list of IDs for the current batch\n",
        "      '''\n",
        "        #initialization\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        Y = np.empty((self.batch_size), dtype=float)\n",
        "\n",
        "        #generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            \n",
        "            #store sample\n",
        "            img = image.load_img(ID, grayscale = False)\n",
        "\n",
        "            #resize\n",
        "            img = img.resize((540, 640))\n",
        "            \n",
        "            #standardize\n",
        "            pixels = asarray(img)\n",
        "            pixels = pixels.astype('float32')\n",
        "            mean, std = pixels.mean(), pixels.std()\n",
        "            X[i,] = (pixels - mean) / std\n",
        "\n",
        "            #store diversity index (Y)\n",
        "            Y[i] = self.values[ID]\n",
        "\n",
        "        return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_O0Sro7rHkI4",
        "colab_type": "text"
      },
      "source": [
        "##Training The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pexB7cB2snP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generators\n",
        "training_generator = DataGenerator(partition['train'], values)\n",
        "validation_generator = DataGenerator(partition['valid'], values)\n",
        "testing_generator = DataGenerator(partition['test'], values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmjQxumJv5nO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define the base model\n",
        "base_model = VGG16(weights = 'imagenet', include_top = False, input_shape = (640, 540, 3))\n",
        "\n",
        "#freeze the base model's layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "#create model\n",
        "model = Sequential()\n",
        "\n",
        "#add the base model\n",
        "model.add(base_model)\n",
        "\n",
        "#add layers for regression\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation= 'linear'))\n",
        "\n",
        "#model summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkeQCVHyaa0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def c_index_metric(y_true, y_pred):\n",
        "  '''determines the concordance while training\n",
        "        y_true: true values\n",
        "        y_pred: predicted values\n",
        "  '''\n",
        "  #compares predicted values with each other\n",
        "  s1 = tf.less(tf.expand_dims(y_pred, -1), y_pred)\n",
        "  s2 = tf.equal(tf.expand_dims(y_pred, -1), y_pred)\n",
        "  s = tf.cast(s2, tf.float32) * 0.5 + tf.cast(s1, tf.float32)\n",
        "\n",
        "  #compares true values with each other\n",
        "  n = tf.less(tf.expand_dims(y_true, -1), y_true)\n",
        "  n = tf.cast(n, tf.float32)\n",
        "\n",
        "  #concordant pairings\n",
        "  s = tf.reduce_sum(tf.multiply(s,n))\n",
        "\n",
        "  #total pairings\n",
        "  n = tf.reduce_sum(n)\n",
        "\n",
        "  #concordant pairings/total pairings\n",
        "  return tf.where(tf.equal(s,0), 0.0, s/n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4SX3QEaw1IJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define the optimizer\n",
        "sgd = SGD(lr = 0.00001, momentum = 0.9, decay = 0.0, nesterov = True)\n",
        "\n",
        "#compile the model\n",
        "model.compile(loss = mean_squared_error, optimizer = sgd, metrics = [c_index_metric])\n",
        "\n",
        "#train model on dataset\n",
        "model.fit_generator(generator=training_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    workers=6, epochs=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZwLiYVPloSi",
        "colab_type": "text"
      },
      "source": [
        "##Evaluating The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b68ynZ84Ch_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#determine the predictions' loss & concordance\n",
        "evaluation = model.evaluate_generator(testing_generator, steps=len(testing_generator), verbose=0)\n",
        "loss = evaluation[0]\n",
        "print(\"loss: \" + str(loss) + \"\\n\" + \"concordance: \" + str(evaluation[1])) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBIdG1rvsa_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get array of true values\n",
        "y_true = []\n",
        "for name in partition[\"test\"]:\n",
        "  y_true.append(values[name])\n",
        "\n",
        "#get array of predicted values\n",
        "y_pred = model.predict_generator(testing_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8udui1E3wOBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def c_index(gt, pred, **kwargs):\n",
        "  '''determines the concordance of the testing data.\n",
        "        gt: ground truth\n",
        "        pred: predictions\n",
        "  '''\n",
        "    assert len(gt) == len(pred), #ground truth and predictions must have same size\n",
        "    s = 0\n",
        "    n = 0\n",
        "\n",
        "    for i, y1 in enumerate(gt):\n",
        "        for j, y2 in enumerate(gt):\n",
        "            if y1 < y2:\n",
        "                s += (pred[i] < pred[j]) + 0.5 * (pred[i] == pred[j])\n",
        "                n += 1\n",
        "\n",
        "    if n == 0:\n",
        "        if 'throw_error' in kwargs:\n",
        "            raise ValueError(f'all ground truth values are equal to {gt[0]}')\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    return s / n\n",
        "\n",
        "print(\"concordance index for testing data: \" + str(c_index(y_true, y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}